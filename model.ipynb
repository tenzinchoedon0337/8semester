{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4002,
     "status": "ok",
     "timestamp": 1610791195915,
     "user": {
      "displayName": "sathish kumar",
      "photoUrl": "",
      "userId": "09811313852492528034"
     },
     "user_tz": -330
    },
    "id": "-JgPqiPJGB0a"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3702,
     "status": "ok",
     "timestamp": 1610791195920,
     "user": {
      "displayName": "sathish kumar",
      "photoUrl": "",
      "userId": "09811313852492528034"
     },
     "user_tz": -330
    },
    "id": "SPWeFH5EGB0n"
   },
   "outputs": [],
   "source": [
    "data_train = 'C:\\\\Users\\\\tsete\\\\OneDrive\\\\Desktop\\\\JPPY2203-Detection of Cardiovascular Diseases in ECG\\\\JPPY2203-Detection of Cardiovascular Diseases in ECG\\\\SOURCE CODE\\\\model\\\\dataset\\\\train'\n",
    "data_test = 'C:\\\\Users\\\\tsete\\\\OneDrive\\\\Desktop\\\\JPPY2203-Detection of Cardiovascular Diseases in ECG\\\\JPPY2203-Detection of Cardiovascular Diseases in ECG\\\\SOURCE CODE\\\\model\\\\dataset\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3489,
     "status": "ok",
     "timestamp": 1610791195921,
     "user": {
      "displayName": "sathish kumar",
      "photoUrl": "",
      "userId": "09811313852492528034"
     },
     "user_tz": -330
    },
    "id": "9h-qH8S-GB0p"
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 5\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47836,
     "status": "ok",
     "timestamp": 1610791240619,
     "user": {
      "displayName": "sathish kumar",
      "photoUrl": "",
      "userId": "09811313852492528034"
     },
     "user_tz": -330
    },
    "id": "7HTI_-XaGB0s",
    "outputId": "040eb250-e8d5-4bdd-c603-6c6465ddbba2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_image_generator = ImageDataGenerator(rescale=1./255)  \n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,directory=data_train,shuffle=True,target_size=(img_height, img_width),class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image_generator = ImageDataGenerator(rescale=1./255)  \n",
    "val_data_gen = val_image_generator .flow_from_directory(batch_size=batch_size,directory=data_test,shuffle=True,target_size=(img_height, img_width),class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model=MobileNet( weights='imagenet',include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xception_net = tf.keras.models.Sequential()\n",
    "\n",
    "xception_net.add(base_model)\n",
    "xception_net.add(GlobalAveragePooling2D())\n",
    "xception_net.add(Dense(10, activation = 'sigmoid'))\n",
    "xception_net.add(Dense(4, activation = 'softmax'))\n",
    "xception_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_net.compile(optimizer= 'adam' , loss= 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = xception_net.fit(train_data_gen, epochs=9,\n",
    "validation_data= val_data_gen,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_net.save('ecg.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_loss_values, label='Validation/Test Loss')\n",
    "line2 = plt.plot(epochs, loss_values, label='Training Loss')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "acc_values = history_dict['accuracy']\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, val_acc_values, label='Validation/Test Accuracy')\n",
    "line2 = plt.plot(epochs, acc_values, label='Training Accuracy')\n",
    "plt.setp(line1, linewidth=2.0, marker = '+', markersize=10.0)\n",
    "plt.setp(line2, linewidth=2.0, marker = '4', markersize=10.0)\n",
    "plt.xlabel('Epochs') \n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.concatenate([val_data_gen.next()[1] for i in range(val_data_gen.__len__())])\n",
    "true_labels=np.argmax(y, axis=-1)\n",
    "prediction= xception_net.predict(val_data_gen, verbose=2)\n",
    "prediction=np.argmax(prediction, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "cm = confusion_matrix(y_true=true_labels, y_pred=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_plot_labels = ['Myocardial_Infarction','Abnormal_Heartbeat','History_of_Myocardial_Infarction','Normal_person']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(true_labels,prediction) \n",
    "print('Accuracy: %.3f' % acc)\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(true_labels,prediction,labels=[1,2], average='micro')\n",
    "print('Precision: %.3f' % precision)\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(true_labels,prediction, average='micro')\n",
    "print('Recall: %.3f' % recall)\n",
    "from sklearn.metrics import f1_score\n",
    "score = f1_score(true_labels,prediction, average='micro')\n",
    "print('F-Measure: %.3f' % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "leaf.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "23f5dd5b32cc72e6113df1e6ff62b26701248167d436f5149b1644bdd1ddd47f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
